{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization commands\n",
    "%matplotlib inline\n",
    "\n",
    "# Important libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy.random as npr # random sampling functions\n",
    "import scipy.stats as sps # statistical functions\n",
    "import matplotlib.pyplot as plt # Matlab plotting framework\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "\n",
    "# Important functions\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numpy import array\n",
    "from scipy.io import loadmat\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "from matplotlib import colors as mcolors\n",
    "colors = dict(mcolors.BASE_COLORS, **mcolors.CSS4_COLORS)\n",
    "\n",
    "# Misc settings\n",
    "sns.set(context=\"poster\", style=\"whitegrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-specifc Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logPost(theta,zHat,oHat):\n",
    "    \n",
    "    mm = oHat.shape[1]\n",
    "    kk = zHat.shape[1]\n",
    "    nn = oHat.shape[0]\n",
    "    \n",
    "    # form the covariance matrix\n",
    "    covM = tril2cov(theta[-mm*(mm+1)/2:],mm)\n",
    "    \n",
    "    # form the beta matrix\n",
    "    betaM = np.reshape(theta[:mm*kk],(kk,mm))\n",
    "    arg = np.transpose(oHat - np.dot(zHat,betaM))\n",
    "    \n",
    "    # compute the log-likelihood at this location in phase space\n",
    "    logLike = -0.5*nn*np.log(np.linalg.det(covM)) - 0.5*np.trace(np.linalg.solve(covM, np.dot(arg,arg.T)))\n",
    "    \n",
    "    return logLike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-prior: Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def priorNorm(x,mu,sigma): \n",
    "    \n",
    "    return np.sum(- 0.5*np.log(2*np.pi) - np.log(sigma) - ((x - mu)**2)/(2*(sigma**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance Matrix\n",
    "Cholesky decomposition of a Hermitian positive-definite matrix is defined as $\\Sigma = LDL^T$, where $L$ is any real-valued lower unit triangular matrix and $D$ is a diagonal matrix with positive elements. We allow the MVN proposal distribution to populate the elements of $L$ in such a way that all proposals provided by the jumping kernel are valid. The code below manipulates these raw MVN proposal locations to ensure the resulting $\\Sigma$ is always a Hermitian positive-definite matrix.\n",
    "\n",
    "$$\\theta^* \\sim\\ MVN(\\theta,\\lambda I)$$\n",
    "\n",
    "$$\\Sigma = LDL^T = \\left[ \\begin{array}{cccc}\n",
    "1 & 0 & 0 \\\\\n",
    "\\theta_{4} & 1 & 0 \\\\\n",
    "\\theta_{5} & \\theta_{6} & 1 \\\\ \\end{array} \\right]\n",
    "\\left[ \\begin{array}{cccc}\n",
    "\\exp(\\theta_{1}) & 0 & 0 \\\\\n",
    "0 & \\exp(\\theta_{2}) & 0 \\\\\n",
    "0 & 0 & \\exp(\\theta_{3}) \\\\ \\end{array} \\right]\n",
    "\\left[ \\begin{array}{cccc}\n",
    "1 & \\theta_{4} & \\theta_{5} \\\\\n",
    "0 & 1 & \\theta_{6} \\\\\n",
    "0 & 0 & 1 \\\\ \\end{array} \\right] =\n",
    "\\left[ \\begin{array}{cccc}\n",
    "\\sigma_{1}^2 & \\rho_{12}\\sigma_{1}\\sigma_{2} & \\rho_{13}\\sigma_{1}\\sigma_{3} \\\\\n",
    "\\rho_{12}\\sigma_{1}\\sigma_{2} & \\sigma_{2}^2 & \\rho_{23}\\sigma_{2}\\sigma_{3} \\\\\n",
    "\\rho_{13}\\sigma_{1}\\sigma_{3} & \\rho_{23}\\sigma_{2}\\sigma_{3} & \\sigma_{3}^2 \\\\ \\end{array} \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tril2cov(x,m):\n",
    "    \n",
    "    D = np.diag(np.exp(x[:m]))\n",
    "    L = np.zeros((m,m))\n",
    "    L[np.tril_indices(m,-1)] = x[-(len(x)-m):]\n",
    "    L[np.diag_indices(m)] = np.ones(m) \n",
    "    \n",
    "    return np.dot(np.dot(L,D),L.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Metropolis Sampler with MVN Block Updates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc(ZH,OH,nn,NN,aa):\n",
    "    \n",
    "    # preallocate standard normal MVN matrix of proposals\n",
    "    mvnJ = npr.multivariate_normal(np.zeros((1,nn)).ravel(),np.eye(nn),NN)\n",
    "    mvnN = np.reshape(np.apply_along_axis(np.linalg.norm,1,mvnJ),(-1,1))\n",
    "    mvnJ = mvnJ/mvnN\n",
    "    \n",
    "    # initialize the chains \n",
    "    pw = np.zeros((1,NN)).ravel()\n",
    "    ns = np.zeros((1,NN)).ravel()\n",
    "    theta = np.zeros((NN,nn))\n",
    "    rndVal = np.log(npr.rand(1,NN)).ravel()\n",
    "    jj = 0\n",
    "    \n",
    "    for i in range(NN):\n",
    "        \n",
    "        if np.less(jj,1):\n",
    "            \n",
    "            jumpVar = npr.randn()\n",
    "            thetaHat = npr.multivariate_normal(np.zeros((1,nn)).ravel(),np.eye(nn))\n",
    "        \n",
    "        pw[i] = 2*jumpVar\n",
    "        thetaStar = np.exp(jumpVar)*mvnJ[i] + thetaHat\n",
    "        logOdds = logPost(thetaStar,ZH,OH) - logPost(thetaHat,ZH,OH)\n",
    "        \n",
    "        if np.less(rndVal[i],logOdds):\n",
    "            \n",
    "            thetaHat = thetaStar\n",
    "            jj += 1\n",
    "        \n",
    "        if np.greater(jj,0):\n",
    "            \n",
    "            jmpDev = np.log(jj) - np.log(i+1) - np.log(aa)\n",
    "            jmpRel = (NN/4 - 1e3)*((i+1)/NN) + 1e3\n",
    "            jumpVar = jumpVar + jmpDev/jmpRel\n",
    "        \n",
    "        ns[i] = jj/(i+1)\n",
    "        theta[i] = thetaHat\n",
    "        \n",
    "    ns = ns.flatten().tolist()\n",
    "    pw = pw.flatten().tolist()\n",
    "    \n",
    "    return theta,ns,pw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Standardization: Z-Scores\n",
    "The computational behavior of MLE and MCMC methods is improved when working with data has been shifted and scaled to have $\\mu=0$ and $\\sigma^2=1$ along each dimension of the data vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# center and/or scale data to have mean = 0 and variance = 1\n",
    "\n",
    "def zscore(data, mode=0):\n",
    "    \n",
    "    mu = np.mean(data)\n",
    "    sig = np.std(data)\n",
    "    \n",
    "    if mode == 0:\n",
    "        \n",
    "        z = (data - mu)/sig\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        z = data/sig\n",
    "    \n",
    "    return z,mu,sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# provide an inverse z-score transformation\n",
    "\n",
    "def zreturn(data, mu, sig, dim=0):\n",
    "    \n",
    "    return sig[dim]*data + mu[dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cityNames = ['HAR','GRI','RNO','TVC','SEA','JAN','BIS','BNA','DFW']\n",
    "# cityNames = ['EYW']\n",
    "\n",
    "# Data file\n",
    "dfTmax = pd.read_pickle('Tmax.pkl')\n",
    "dfTmin = pd.read_pickle('Tmin.pkl')\n",
    "dfVmax = pd.read_pickle('Vmax.pkl')\n",
    "dfClimo = pd.read_pickle('Climo.pkl')\n",
    "\n",
    "chainNum = 0\n",
    "mdl = 'ARCN'\n",
    "\n",
    "burnVal = 1e6 # burn-in period\n",
    "warmVal = burnVal # number of post-burn-in samples\n",
    "thinVal = warmVal/100 # number target samples retained post-burn-in\n",
    "\n",
    "accT = 0.234\n",
    "lags = 100\n",
    "    \n",
    "thinFrac = thinVal/warmVal; # fraction retained from warmed samples\n",
    "N = warmVal + burnVal\n",
    "\n",
    "ARList = ['ARN1', 'ARN2', 'ARN3', 'ARN4', 'ARN5', 'ARN6','ARP1', 'ARP2', 'ARP3', 'ARP4', 'ARP5', 'ARP6']\n",
    "MBList = ['MBN1', 'MBN2', 'MBN3', 'MBN4', 'MBN5', 'MBN6','MBP1', 'MBP2', 'MBP3', 'MBP4', 'MBP5', 'MBP6']\n",
    "SRList = ARList + MBList\n",
    "fullList = ['ARCN','MBCN','OBS'] + SRList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time: 98.14369243216699[min]\n",
      "Mean sampling rate: 3056.74254315781 [proposals/sec]\n",
      "Mean sampling time per 10^6 proposals: 5.45242735734261 [min]\n"
     ]
    }
   ],
   "source": [
    "t1 = time.clock()\n",
    "\n",
    "for cIdx, cityStr in enumerate(cityNames):\n",
    "    \n",
    "    dfT = dfTmax[dfTmax['City']==cityStr]\n",
    "    dft = dfTmin[dfTmin['City']==cityStr]\n",
    "    dfV = dfVmax[dfVmax['City']==cityStr]\n",
    "\n",
    "    # ubiquitous log-transformation of the data\n",
    "    dfT.loc[:,fullList] = np.log(dfT.loc[:,fullList])\n",
    "    dft.loc[:,fullList] = np.log(dft.loc[:,fullList])\n",
    "    dfV.loc[:,fullList] = np.log(dfV.loc[:,fullList])\n",
    "    \n",
    "    dfT = dfT.reindex_axis(sorted(dfT.columns), axis=1)\n",
    "    dft = dft.reindex_axis(sorted(dft.columns), axis=1)\n",
    "    dfV = dfV.reindex_axis(sorted(dfV.columns), axis=1)\n",
    "\n",
    "    T = array(dfT.loc[dfT['Type']=='Train', 'OBS']).reshape(-1,1)\n",
    "    t = array(dft.loc[dft['Type']=='Train', 'OBS']).reshape(-1,1)\n",
    "    V = array(dfV.loc[dfV['Type']=='Train', 'OBS']).reshape(-1,1)\n",
    "\n",
    "    obs = np.concatenate((T,t,V),axis=1)\n",
    "    \n",
    "    del T, t, V\n",
    "    \n",
    "    T = array(dfT.loc[dfT['Type']=='Train', mdl]).reshape(-1,1)\n",
    "    t = array(dft.loc[dft['Type']=='Train', mdl]).reshape(-1,1)\n",
    "    V = array(dfV.loc[dfV['Type']=='Train', mdl]).reshape(-1,1)\n",
    "\n",
    "    data = np.concatenate((T,t,V),axis=1)\n",
    "\n",
    "    obs = pd.DataFrame(obs)\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    X,xMu,xStd = zscore(data)\n",
    "    O,oMu,oStd = zscore(obs)\n",
    "    \n",
    "    xMu = array(xMu.tolist()).reshape(1,-1)\n",
    "    xStd = array(xStd.tolist()).reshape(1,-1)\n",
    "    oMu = array(oMu.tolist()).reshape(1,-1)\n",
    "    oStd = array(oStd.tolist()).reshape(1,-1)\n",
    "    \n",
    "    X['D'] = 1\n",
    "    cols = X.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    X = X[cols]\n",
    "\n",
    "    X = X.as_matrix()\n",
    "    O = O.as_matrix()\n",
    "    mm = O.shape[1]\n",
    "    kk = X.shape[1]\n",
    "    nParm = kk*mm + mm*(mm+1)/2 # number of parameters\n",
    "\n",
    "    th,ns,pw = mcmc(X,O,int(nParm),int(N),accT) \n",
    "    \n",
    "    TH = pd.DataFrame(th)\n",
    "    TH = TH.rename(columns = lambda x : 'B_' + str(x))\n",
    "    TH['City'] = cityStr\n",
    "    TH['Accept'] = ns\n",
    "    TH['Width'] = pw\n",
    "    TH['Proposal'] = TH.index.tolist()\n",
    "    TH['Chain'] = chainNum\n",
    "    \n",
    "    if cIdx == 0:\n",
    "    \n",
    "        dfTH = TH.copy()\n",
    "        XMU = xMu\n",
    "        XSTD = xStd\n",
    "        OMU = oMu\n",
    "        OSTD = oStd\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        XMU = np.concatenate((XMU,xMu))\n",
    "        XSTD = np.concatenate((XSTD,xStd))\n",
    "        OMU = np.concatenate((OMU,oMu))\n",
    "        OSTD = np.concatenate((OSTD,oStd))\n",
    "        dfTH = pd.concat([dfTH,TH], ignore_index=True)\n",
    "    \n",
    "    # del th, ns, pw, xMu, xStd, oMu, oStd, TH, X, O, cols\n",
    "    \n",
    "XMU = pd.DataFrame(XMU, columns = ['Tmax','Tmin','Vmax'])\n",
    "XSTD = pd.DataFrame(XSTD, columns = ['Tmax','Tmin','Vmax'])\n",
    "OMU = pd.DataFrame(OMU, columns = ['Tmax','Tmin','Vmax'])\n",
    "OSTD = pd.DataFrame(OSTD, columns = ['Tmax','Tmin','Vmax'])\n",
    "\n",
    "XMU['City'] = cityNames\n",
    "XMU['Type'] = 'x'\n",
    "XMU['Stat'] = 'mu'\n",
    "\n",
    "XSTD['City'] = cityNames\n",
    "XSTD['Type'] = 'x'\n",
    "XSTD['Stat'] = 'std'\n",
    "\n",
    "OMU['City'] = cityNames\n",
    "OMU['Type'] = 'o'\n",
    "OMU['Stat'] = 'mu'\n",
    "\n",
    "OSTD['City'] = cityNames\n",
    "OSTD['Type'] = 'o'\n",
    "OSTD['Stat'] = 'std'\n",
    "\n",
    "dfZS = pd.concat([XMU,XSTD,OMU,OSTD], ignore_index=True)\n",
    "\n",
    "dfTH.to_pickle(mdl + '_params_' + str(chainNum) + '.pkl')\n",
    "dfZS.to_pickle(mdl + '_zscores.pkl')\n",
    "\n",
    "t2 = time.clock() - t1\n",
    "tt = N*len(cityNames)/t2\n",
    "s0 = 'Sampling time: ' + repr(t2/60) + '[min]'\n",
    "s1 = 'Mean sampling rate: ' + repr(tt) + ' [proposals/sec]'\n",
    "s2 = 'Mean sampling time per 10^6 proposals: ' + repr(1e6/(tt*60)) + ' [min]'\n",
    "print(s0)\n",
    "print(s1)\n",
    "print(s2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
